{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "목표7 : 라벨(나이)에 맞게 softmax 처리를 해보자\n",
    "    \n",
    "목표6 : 소스 정리 및 learningrate 등의 값 조절 등을 하면서 실험\n",
    "\n",
    "목표5 : batch 처리\n",
    "    \n",
    "목표4 : 파일/라벨의 수를 실제처럼 확대\n",
    "\n",
    "목표3 : pooling, dropout을 넣어보자\n",
    "\n",
    "목표2 : crossentroy를 해서 loss를 줄이는 처리\n",
    "\n",
    "목표1 : 이미지를 하나 읽어 들이고 conv layer 2번 + fc layer 1번 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face00001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face01001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face02001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face03001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face04001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face05001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face06001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face07001.png\n",
      "['c:/tmp/Temp_data_Set/Test_Dataset_csv/label.csv']\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'c:/tmp/Temp_data_Set/Test_Dataset_png/'\n",
    "image_list = os.listdir(image_dir)\n",
    "image_list.sort()    # sort()는 return이 없음\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    image_list[i] = image_dir + image_list[i]\n",
    "    if i%1000 == 0:\n",
    "        print(image_list[i])\n",
    "\n",
    "label_dir = 'c:/tmp/Temp_data_Set/Test_Dataset_csv/label.csv'\n",
    "label_list = [label_dir]\n",
    "print(label_list)\n",
    "\n",
    "imagename_queue = tf.train.string_input_producer(image_list)\n",
    "labelname_queue = tf.train.string_input_producer(label_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 상수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_height = 61\n",
    "image_width = 49\n",
    "\n",
    "shuffle_batch_size = 32\n",
    "\n",
    "label_class_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_reader = tf.WholeFileReader()\n",
    "label_reader = tf.TextLineReader()\n",
    "image_key, image_value = image_reader.read(imagename_queue)\n",
    "label_key, label_value = label_reader.read(labelname_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_decoded = tf.cast(tf.image.decode_png(image_value), tf.float32)\n",
    "label_decoded = tf.cast(tf.decode_csv(label_value, record_defaults=[[0]]), tf.float32)\n",
    "#print(image)\n",
    "\n",
    "label = tf.reshape(label_decoded,[1])\n",
    "image = tf.reshape(image_decoded,[image_height, image_width, 1])\n",
    "\n",
    "x, y_true_cls_batch = tf.train.shuffle_batch(tensors=[image, label], batch_size=shuffle_batch_size, num_threads=4, capacity=5000, min_after_dequeue=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# one_hot encoding style로 변경 : python에 약해서 짧게 안되네 - tensorflow로만 해야 하는데 잘 안되네"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# label class 값을 one-hot encoding값으로 변환\n",
    "# 0 <= label < label_class_size\n",
    "# http://blogs.candoerz.com/question/122513/tensorflow-one-hot-encoder.aspx\n",
    "# http://stackoverflow.com/questions/33681517/tensorflow-one-hot-encoder\n",
    "sparse_labels = tf.reshape(tf.cast(y_true_cls_batch, tf.int32), [-1, 1])\n",
    "derived_size = tf.shape(sparse_labels)[0]\n",
    "indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\n",
    "concated = tf.concat([indices, sparse_labels], 1)    # tf1.0\n",
    "outshape = tf.concat([tf.reshape(derived_size, [1]), tf.reshape(label_class_size, [1])], 0)    # tf1.0\n",
    "y_true = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "# one-hot encoding값을 readable 값으로 바꿈 : y_true_cls_batch의 shape를 조정하는 대신 y_pred_cls와 동일하게 처리\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 변수 (naming convention은 tensorflow.org의 MNIST예제 style임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,32]))\n",
    "b_conv1 = tf.Variable(tf.zeros([32]))\n",
    "\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5,5,32,64]))\n",
    "b_conv2 = tf.Variable(tf.zeros([64]))\n",
    "\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([image_width*image_height*64, 50]))\n",
    "b_fc1 = tf.Variable(tf.zeros([50]))\n",
    "\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([50, 100]))\n",
    "b_fc2 = tf.Variable(tf.zeros([100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, image_width, image_height, 1])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 모델 (naming convention은 tensorflow.org의 MNIST예제 style임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding=\"SAME\") + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding=\"SAME\") + b_conv2)\n",
    "h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, image_width*image_height*64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_3:0\", shape=(32, 100), dtype=float32)\n",
      "Tensor(\"SparseToDense_1:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y_conv)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_true = tf.placeholder(tf.float32, [None, label_class_size])\n",
    "#y_true_cls = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=y_conv)\n",
    "# one-hot encoding값을 readable 값으로 바꿈\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_min(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "train = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction한 값과 label값을 비교 : True/False 리스트\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "\n",
    "# True/False 리스트를 실수형으로 casting한다.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "b'c:/tmp/Temp_data_Set/Test_Dataset_png/Face03378.png'\n",
      "[77 29  0  3 39 39 39  3 39 39 86 39 39 57 39 39 39 99  3 39 99  0 39  3 39\n",
      " 99  3 39 39 39 57 57]\n",
      "[28 28 28 10 51 51 28 28 28 51 28 28 28 51 75 28 28 51 28 28 28 28 28  5 28\n",
      " 28 28 51 16 51 28 51]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "b'c:/tmp/Temp_data_Set/Test_Dataset_png/Face00196.png'\n",
      "[57 31 39 57 39 39 57 39 99 39 39  3 86 39 44  3 39 39 44 99 39 39  3 39 39\n",
      "  3 44 39 39 57  6 39]\n",
      "[51 28 28 28 28 28 28 28 28 51 51  5 28 28 51 28 28 28 28 75 28 28 51 28 28\n",
      " 28 51 28 51 51 28 28]\n",
      "training done\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"started\")\n",
    "    coord = tf.train.Coordinator()\n",
    "    thread = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(100):\n",
    "#        print(sess.run(image_key))\n",
    "#        print(sess.run(image_key))\n",
    "        sess.run(train, {keep_prob: 0.7})\n",
    "#        sess.run(train)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            #if train==True:\n",
    "            _loss = sess.run(loss, {keep_prob: 0.7})\n",
    "            _accuracy = sess.run(accuracy, {keep_prob: 0.7})\n",
    "            #if release_mode==Train:\n",
    "            #result = sess.run(pred, {keep_prob: 1.0})\n",
    "\n",
    "            print(\"-----------------\")\n",
    "            print(\"loss: \", _loss)\n",
    "            print(\"accuracy: \", _accuracy)\n",
    "\n",
    "#            print(sess.run(image_key))\n",
    "            print(sess.run(y_pred_cls, {keep_prob: 0.7}))\n",
    "            print(sess.run(y_true_cls, {keep_prob: 0.7}))\n",
    "\n",
    "#    print(image)\n",
    "\n",
    "#    Image.fromarray(image).show()\n",
    "\n",
    "    print(\"training done\")\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
