{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "목표8 : 학습 정보를 저장/읽기 처리를 해보자\n",
    "\n",
    "목표7 : 라벨(나이)에 맞게 softmax 처리를 해보자\n",
    "    \n",
    "목표6 : 소스 정리 및 learningrate 등의 값 조절 등을 하면서 실험\n",
    "\n",
    "목표5 : batch 처리\n",
    "    \n",
    "목표4 : 파일/라벨의 수를 실제처럼 확대\n",
    "\n",
    "목표3 : pooling, dropout을 넣어보자\n",
    "\n",
    "목표2 : crossentroy를 해서 loss를 줄이는 처리\n",
    "\n",
    "목표1 : 이미지를 하나 읽어 들이고 conv layer 2번 + fc layer 1번 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face00001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face01001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face02001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face03001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face04001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face05001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face06001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face07001.png\n",
      "['c:/tmp/Temp_data_Set/Test_Dataset_csv/Label.csv']\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'c:/tmp/Temp_data_Set/Test_Dataset_png/'\n",
    "image_list = os.listdir(image_dir)\n",
    "image_list.sort()    # sort()는 return이 없음\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    image_list[i] = image_dir + image_list[i]\n",
    "    if i%1000 == 0:\n",
    "        print(image_list[i])\n",
    "\n",
    "# linux에서는 대소문자 주의 : Lavel.csv\n",
    "label_dir = 'c:/tmp/Temp_data_Set/Test_Dataset_csv/Label.csv'\n",
    "label_list = [label_dir]\n",
    "print(label_list)\n",
    "\n",
    "imagename_queue = tf.train.string_input_producer(image_list)\n",
    "labelname_queue = tf.train.string_input_producer(label_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 상수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_height = 61\n",
    "image_width = 49\n",
    "\n",
    "shuffle_batch_size = 32\n",
    "\n",
    "label_class_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_reader = tf.WholeFileReader()\n",
    "label_reader = tf.TextLineReader()\n",
    "image_key, image_value = image_reader.read(imagename_queue)\n",
    "label_key, label_value = label_reader.read(labelname_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_decoded = tf.cast(tf.image.decode_png(image_value), tf.float32)\n",
    "label_decoded = tf.cast(tf.decode_csv(label_value, record_defaults=[[0]]), tf.float32)\n",
    "#print(image)\n",
    "\n",
    "label = tf.reshape(label_decoded,[1])\n",
    "image = tf.reshape(image_decoded,[image_height, image_width, 1])\n",
    "\n",
    "x, y_true_cls_batch = tf.train.shuffle_batch(tensors=[image, label], batch_size=shuffle_batch_size, num_threads=4, capacity=5000, min_after_dequeue=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# one_hot encoding style로 변경 : python에 약해서 짧게 안되네 - tensorflow로만 해야 하는데 잘 안되네"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# label class 값을 one-hot encoding값으로 변환 : tensor는 numpy로 처리할 수 없고 tensor로만 처리해야 함\n",
    "#     http://stackoverflow.com/questions/33681517/tensorflow-one-hot-encoder (오류 수정본 사용)\n",
    "sparse_labels = tf.reshape(tf.cast(y_true_cls_batch, tf.int32), [-1, 1])\n",
    "derived_size = tf.shape(sparse_labels)[0]\n",
    "indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\n",
    "concated = tf.concat([indices, sparse_labels], 1)    # tf1.0\n",
    "outshape = tf.concat([tf.reshape(derived_size, [1]), tf.reshape(label_class_size, [1])], 0)    # tf1.0\n",
    "y_true = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "# one-hot encoding값을 readable 값으로 바꿈 : y_true_cls_batch의 shape를 조정하는 대신 y_pred_cls와 동일하게 처리\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 변수 (naming convention은 tensorflow.org의 MNIST예제 style임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,32]), name='W_conv1')\n",
    "b_conv1 = tf.Variable(tf.zeros([32]), name='b_conv1')\n",
    "\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5,5,32,64]), name='W_conv2')\n",
    "b_conv2 = tf.Variable(tf.zeros([64]), name='b_conv2')\n",
    "\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([image_width*image_height*64, 50]), name='W_fc1')\n",
    "b_fc1 = tf.Variable(tf.zeros([50]), name='b_fc1')\n",
    "\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([50, 100]), name='W_fc2')\n",
    "b_fc2 = tf.Variable(tf.zeros([100]), name='b_fc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, image_width, image_height, 1])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_list = [W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2]\n",
    "saver = tf.train.Saver(param_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 모델 (naming convention은 tensorflow.org의 MNIST예제 style임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding=\"SAME\") + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding=\"SAME\") + b_conv2)\n",
    "h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, image_width*image_height*64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_3:0\", shape=(32, 100), dtype=float32)\n",
      "Tensor(\"SparseToDense:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y_conv)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_true = tf.placeholder(tf.float32, [None, label_class_size])\n",
    "#y_true_cls = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=y_conv)\n",
    "# one-hot encoding값을 readable 값으로 바꿈\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_min(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "train = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction한 값과 label값을 비교 : True/False 리스트\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "\n",
    "# True/False 리스트를 실수형으로 casting한다.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sync가 안맞아서 prediction과 supervised label과 비교가 안됨\n",
    "y_pred_true_cls = tf.stack([y_pred_cls,y_true_cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "None\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "tensorflow 계산이 별도로 이루어지기 때문에 accuracy와 synch가 안맞는건가!! : 어떻게 맞추지?\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "prediction:  [95 21 83 89 89 95 19 19 95 95 95 54 30 53 21 62 95 95 53 95 95 95 19 95 22\n",
      " 95 22 95 19 19 30 62]\n",
      "supervised:  [ 1 28 16 28  1 51 51 28 28 75 28 28 28 16 28 28 28 28 28  5 51 28 28 28 28\n",
      " 10 28 28 28 51 75 51]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "tensorflow 계산이 별도로 이루어지기 때문에 accuracy와 synch가 안맞는건가!! : 어떻게 맞추지?\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "prediction:  [83 95 62 21 22 19 67 30 30 67 95 30 95 95 95 95 95 19 95 30 54 40 19 22 70\n",
      " 95 54 95 19 53 95 77]\n",
      "supervised:  [28 28 16  5 28 28 28 28 28  5 28 51 28 28 51 28 10 51 28 16 28 10 28 28 51\n",
      " 28 28 28 28 28 28 28]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "tensorflow 계산이 별도로 이루어지기 때문에 accuracy와 synch가 안맞는건가!! : 어떻게 맞추지?\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "prediction:  [84 95 19 39 84 67 95 95 19 88 53 61 95 19 19 95 19 95 30 67 19 95 95 40 95\n",
      " 19 24 19 19 19 95 22]\n",
      "supervised:  [28 28 28 28 75  5 16 16 28 28 28 51 10 28 28 28 28 51 16 28  5 28 28 28 28\n",
      " 51 75 51 28 51 16 28]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "tensorflow 계산이 별도로 이루어지기 때문에 accuracy와 synch가 안맞는건가!! : 어떻게 맞추지?\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "prediction:  [95 19 21 95 19 21 95 39 12 22 19 39 30 19 19 95 95 19 30 22 19 19 77 95 30\n",
      " 19 79 95 30 19 19 30]\n",
      "supervised:  [28 51 28 28 16 28 28 28  5 51 28 28 16 75 51 51 51 28 28 51 28 51 28 51 28\n",
      " 28 28 28 75 28 28 28]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "tensorflow 계산이 별도로 이루어지기 때문에 accuracy와 synch가 안맞는건가!! : 어떻게 맞추지?\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "prediction:  [95 30 19 22 22 61 88 19 30 19 95 30 19 19 62 95 95 30 19 54 95 39 19 19 19\n",
      " 95 95 62 21 53 22 53]\n",
      "supervised:  [10 51 28  5 28 51 51 28 28 28 51 51 28 16 28 28 16  5 28 28 28 16 51 28 51\n",
      " 51 28 51 28 51 51 28]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "tensorflow 계산이 별도로 이루어지기 때문에 accuracy와 synch가 안맞는건가!! : 어떻게 맞추지?\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "prediction:  [54 22 21 95  2 61 62 19 30 95 53 62 53 19 19 21 54 62 67 19 95 30 77 83 95\n",
      " 95 61 30 95 54 19 95]\n",
      "supervised:  [28 28 28 51 51 28 51 28 28 28 28  5 28 75 28 10 51 28 28 28 28 28 51 51 28\n",
      " 28 51 28 51 28 28 51]\n",
      "Model saved in file: ./checkpoints/cnn_excercise-500\n",
      "training done\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"started\")\n",
    "    coord = tf.train.Coordinator()\n",
    "    thread = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    latest_filename = tf.train.latest_checkpoint(\"./checkpoints/\")\n",
    "    print(latest_filename)\n",
    "    if latest_filename != None :\n",
    "        saver.restore(sess, latest_filename)\n",
    "        print(\"Model restored.\")\n",
    "\n",
    "    for i in range(500+1):\n",
    "#        print(sess.run(image_key))\n",
    "#        print(sess.run(image_key))\n",
    "        sess.run(train, {keep_prob: 0.7})\n",
    "#        sess.run(train)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            #if train==True:\n",
    "            _loss, _accuracy, _y_pred_true_cls = sess.run([loss, accuracy, y_pred_true_cls], {keep_prob: 0.7})\n",
    "            #if release_mode==Train:\n",
    "            #result = sess.run(pred, {keep_prob: 1.0})\n",
    "\n",
    "            print(\"-----------------\")\n",
    "            print(\"loss: \", _loss)\n",
    "            print(\"accuracy: \", _accuracy)\n",
    "            print(np.equal(_y_pred_true_cls[0],_y_pred_true_cls[1]))\n",
    "            print(\"prediction: \", _y_pred_true_cls[0])\n",
    "            print(\"supervised: \", _y_pred_true_cls[1])\n",
    "\n",
    "#            print(sess.run(image_key))\n",
    "#            print(sess.run(y_pred_cls, {keep_prob: 0.7}))\n",
    "#            print(sess.run(y_true_cls, {keep_prob: 0.7}))\n",
    "        if i > 0 and i % 500 == 0:\n",
    "            save_path = saver.save(sess, './checkpoints/cnn_excercise', global_step=i)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "#    print(image)\n",
    "\n",
    "#    Image.fromarray(image).show()\n",
    "\n",
    "    print(\"training done\")\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
