{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "목표8 : 학습 정보를 저장/읽기 처리를 해보자\n",
    "\n",
    "목표7 : 라벨(나이)에 맞게 softmax 처리를 해보자\n",
    "    \n",
    "목표6 : 소스 정리 및 learningrate 등의 값 조절 등을 하면서 실험\n",
    "\n",
    "목표5 : batch 처리\n",
    "    \n",
    "목표4 : 파일/라벨의 수를 실제처럼 확대\n",
    "\n",
    "목표3 : pooling, dropout을 넣어보자\n",
    "\n",
    "목표2 : crossentroy를 해서 loss를 줄이는 처리\n",
    "\n",
    "목표1 : 이미지를 하나 읽어 들이고 conv layer 2번 + fc layer 1번 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face00001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face01001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face02001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face03001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face04001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face05001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face06001.png\n",
      "c:/tmp/Temp_data_Set/Test_Dataset_png/Face07001.png\n",
      "['c:/tmp/Temp_data_Set/Test_Dataset_csv/label.csv']\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'c:/tmp/Temp_data_Set/Test_Dataset_png/'\n",
    "image_list = os.listdir(image_dir)\n",
    "image_list.sort()    # sort()는 return이 없음\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    image_list[i] = image_dir + image_list[i]\n",
    "    if i%1000 == 0:\n",
    "        print(image_list[i])\n",
    "\n",
    "label_dir = 'c:/tmp/Temp_data_Set/Test_Dataset_csv/label.csv'\n",
    "label_list = [label_dir]\n",
    "print(label_list)\n",
    "\n",
    "imagename_queue = tf.train.string_input_producer(image_list)\n",
    "labelname_queue = tf.train.string_input_producer(label_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 상수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_height = 61\n",
    "image_width = 49\n",
    "\n",
    "shuffle_batch_size = 32\n",
    "\n",
    "label_class_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_reader = tf.WholeFileReader()\n",
    "label_reader = tf.TextLineReader()\n",
    "image_key, image_value = image_reader.read(imagename_queue)\n",
    "label_key, label_value = label_reader.read(labelname_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_decoded = tf.cast(tf.image.decode_png(image_value), tf.float32)\n",
    "label_decoded = tf.cast(tf.decode_csv(label_value, record_defaults=[[0]]), tf.float32)\n",
    "#print(image)\n",
    "\n",
    "label = tf.reshape(label_decoded,[1])\n",
    "image = tf.reshape(image_decoded,[image_height, image_width, 1])\n",
    "\n",
    "x, y_true_cls_batch = tf.train.shuffle_batch(tensors=[image, label], batch_size=shuffle_batch_size, num_threads=4, capacity=5000, min_after_dequeue=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# one_hot encoding style로 변경 : python에 약해서 짧게 안되네 - tensorflow로만 해야 하는데 잘 안되네"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# label class 값을 one-hot encoding값으로 변환 : tensor는 numpy로 처리할 수 없고 tensor로만 처리해야 함\n",
    "#     http://stackoverflow.com/questions/33681517/tensorflow-one-hot-encoder (오류 수정본 사용)\n",
    "sparse_labels = tf.reshape(tf.cast(y_true_cls_batch, tf.int32), [-1, 1])\n",
    "derived_size = tf.shape(sparse_labels)[0]\n",
    "indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\n",
    "concated = tf.concat([indices, sparse_labels], 1)    # tf1.0\n",
    "outshape = tf.concat([tf.reshape(derived_size, [1]), tf.reshape(label_class_size, [1])], 0)    # tf1.0\n",
    "y_true = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "# one-hot encoding값을 readable 값으로 바꿈 : y_true_cls_batch의 shape를 조정하는 대신 y_pred_cls와 동일하게 처리\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 변수 (naming convention은 tensorflow.org의 MNIST예제 style임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,32]), name='W_conv1')\n",
    "b_conv1 = tf.Variable(tf.zeros([32]), name='b_conv1')\n",
    "\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5,5,32,64]), name='W_conv2')\n",
    "b_conv2 = tf.Variable(tf.zeros([64]), name='b_conv2')\n",
    "\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([image_width*image_height*64, 50]), name='W_fc1')\n",
    "b_fc1 = tf.Variable(tf.zeros([50]), name='b_fc1')\n",
    "\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([50, 100]), name='W_fc2')\n",
    "b_fc2 = tf.Variable(tf.zeros([100]), name='b_fc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, image_width, image_height, 1])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_list = [W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2]\n",
    "saver = tf.train.Saver(param_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 모델 (naming convention은 tensorflow.org의 MNIST예제 style임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding=\"SAME\") + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding=\"SAME\") + b_conv2)\n",
    "h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, image_width*image_height*64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_3:0\", shape=(32, 100), dtype=float32)\n",
      "Tensor(\"SparseToDense:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y_conv)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_true = tf.placeholder(tf.float32, [None, label_class_size])\n",
    "#y_true_cls = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=y_conv)\n",
    "# one-hot encoding값을 readable 값으로 바꿈\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_min(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "train = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction한 값과 label값을 비교 : True/False 리스트\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "\n",
    "# True/False 리스트를 실수형으로 casting한다.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "./checkpoints/cnn_excercise-500\n",
      "Model restored.\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "[80 90 90 90 23 90 90 47 90 91 23 23  3 90 90 90 47 23 40 82 26 90 88  7 90\n",
      " 91 90 47 82 91 23 91]\n",
      "[28 28 28 28 28 51 28 51 16 28 51 28 28 16 28 51 28 28 16 28 28  1 28 51 28\n",
      " 28 28 51 28 51 28 28]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "[77 24 91 77 91  3 90 24 64 94 67 80 23 90 90 91 88 23 88 89 82 90 24 88 91\n",
      " 90 90 94 11 23 90 64]\n",
      "[51 28 28 28 28 28 28 16 28 28 28 28 28 28 51 51 51 10 28 28 28 51 16 28 28\n",
      " 28 28 51 51 51 28 28]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "[40 47 90  7  7 90 11 64 47 82 90 82 90 88 91 40  7 82 11 88 64 97  3 40 24\n",
      " 90  3 90 90 82  3 94]\n",
      "[51 28 28 28 28 16 28 28 28 28 28 51 28 28  5 51 16 28 28 51 16 51 28 51 28\n",
      "  1 28 28 28 28 16 28]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "[90 11 90 68  7 90 90 23 23 90 91  7 91 90 55 23 82 90  3 90 70 90 91 88 88\n",
      " 94  3  7 90 64 90  7]\n",
      "[28 51 28 28 28 28 51 51 28 28 28 75 51 28 28 51 28  5 28 51 75 28 51 28 28\n",
      " 28 28 75 28 28 51 28]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "[94 77 94 94 88 90 90 94 88 68 91  3 23 90 23 47 90 94 91 90 88 90 68 23 11\n",
      " 23 24 82 80 90 82 90]\n",
      "[28 28 10 28 28 28 28 28 51 28 51 28 28 10 28 51 28 28 28 28 28 28 16 28 28\n",
      " 28 28 28 51 51 28  1]\n",
      "-----------------\n",
      "loss:  4.62221\n",
      "accuracy:  0.0\n",
      "[42 88 23 40 88 23 90 90 90 91 23 90 90  3  3 47 26 42 82 61 95 64 64 90 80\n",
      " 80 88 90 23 23 90 90]\n",
      "[28 51 28 75 28 28 28 28 16 51 51 10 28 51 51 28 28 16 51 75 51 28 28 28 51\n",
      " 28 28 28 51 51 28 51]\n",
      "Model saved in file: ./checkpoints/cnn_excercise-500\n",
      "training done\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"started\")\n",
    "    coord = tf.train.Coordinator()\n",
    "    thread = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    latest_filename = tf.train.latest_checkpoint(\"./checkpoints/\")\n",
    "    print(latest_filename)\n",
    "    if latest_filename != None :\n",
    "        saver.restore(sess, latest_filename)\n",
    "        print(\"Model restored.\")\n",
    "\n",
    "    for i in range(500+1):\n",
    "#        print(sess.run(image_key))\n",
    "#        print(sess.run(image_key))\n",
    "        sess.run(train, {keep_prob: 0.7})\n",
    "#        sess.run(train)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            #if train==True:\n",
    "            _loss = sess.run(loss, {keep_prob: 0.7})\n",
    "            _accuracy = sess.run(accuracy, {keep_prob: 0.7})\n",
    "            #if release_mode==Train:\n",
    "            #result = sess.run(pred, {keep_prob: 1.0})\n",
    "\n",
    "            print(\"-----------------\")\n",
    "            print(\"loss: \", _loss)\n",
    "            print(\"accuracy: \", _accuracy)\n",
    "\n",
    "#            print(sess.run(image_key))\n",
    "            print(sess.run(y_pred_cls, {keep_prob: 0.7}))\n",
    "            print(sess.run(y_true_cls, {keep_prob: 0.7}))\n",
    "        if i > 0 and i % 500 == 0:\n",
    "            save_path = saver.save(sess, './checkpoints/cnn_excercise', global_step=i)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "#    print(image)\n",
    "\n",
    "#    Image.fromarray(image).show()\n",
    "\n",
    "    print(\"training done\")\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
